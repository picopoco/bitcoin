{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import shutil\n",
    "import tensorflow.contrib.learn as tflearn\n",
    "import tensorflow.contrib.layers as tflayers\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "import tensorflow.contrib.metrics as metrics\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "from tensorflow.contrib.learn.python.learn.utils import saved_model_export_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tf.__version__', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 5\n",
    "DEFAULTS = [[0.0] for x in range(SEQ_LEN)]\n",
    "BATCH_SIZE = 20\n",
    "EPOCH_SIZE = 100\n",
    "TIMESERIES_COL = 'rawdata'\n",
    "NUM_LABELS = 1\n",
    "NUM_FEATURES = SEQ_LEN - NUM_LABELS\n",
    "TRAIN_GCS_PATH = 'gs://gcpkr-bitcoin-ml/preprocessing/train/kaggle_sample_train.csv'\n",
    "EVAL_GCS_PATH = 'gs://gcpkr-bitcoin-ml/preprocessing/eval/kaggle_sample_eval.csv'\n",
    "LSTM_SIZE = 5\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "OPTIMIZER = 'SGD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dataset(filename, mode=tf.contrib.learn.ModeKeys.TRAIN):  \n",
    "    def _input_fn():\n",
    "        num_epochs = EPOCH_SIZE if mode == tf.contrib.learn.ModeKeys.TRAIN else 1\n",
    "        input_file_names = tf.train.match_filenames_once(filename)\n",
    "        filename_queue = tf.train.string_input_producer(\n",
    "            input_file_names, num_epochs=num_epochs, shuffle=False)\n",
    "        reader = tf.TextLineReader()\n",
    "        _, value = reader.read_up_to(filename_queue, num_records=BATCH_SIZE)\n",
    "        value_column = tf.expand_dims(value, -1)\n",
    "        all_data = tf.decode_csv(value_column, record_defaults=DEFAULTS)\n",
    "        inputs = all_data[:len(all_data)-NUM_LABELS]\n",
    "        label = all_data[len(all_data)-NUM_LABELS : ]\n",
    "        inputs = tf.concat(inputs, axis=1)\n",
    "        label = tf.concat(label, axis=1)\n",
    "        return {TIMESERIES_COL: inputs}, label\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(features, targets, mode):\n",
    "    x = tf.split(features[TIMESERIES_COL], NUM_FEATURES, 1) # sequence 형태로 변이\n",
    "    lstm_cell = rnn.BasicLSTMCell(LSTM_SIZE, forget_bias=1.0)\n",
    "    outputs, _ = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    outputs = outputs[-1]\n",
    "    weight = tf.Variable(tf.random_normal([LSTM_SIZE, NUM_LABELS]))\n",
    "    bias = tf.Variable(tf.random_normal([NUM_LABELS]))\n",
    "    predictions = tf.matmul(outputs, weight) + bias\n",
    "    \n",
    "    if mode == tf.contrib.learn.ModeKeys.TRAIN or mode == tf.contrib.learn.ModeKeys.EVAL:\n",
    "        loss = tf.losses.mean_squared_error(targets, predictions)\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            optimizer=OPTIMIZER)\n",
    "        eval_metric_ops = {\n",
    "            \"rmse\": tf.metrics.root_mean_squared_error(targets, predictions)\n",
    "            }\n",
    "    else:\n",
    "        loss = None\n",
    "        train_op = None\n",
    "        eval_metric_ops = None\n",
    "  \n",
    "    predictions_dict = {\"predicted\": predictions}\n",
    "  \n",
    "    return tflearn.ModelFnOps(\n",
    "        mode=mode,\n",
    "        predictions=predictions_dict,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train():\n",
    "    return read_dataset(TRAIN_GCS_PATH, mode=tf.contrib.learn.ModeKeys.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_valid():\n",
    "    return read_dataset(EVAL_GCS_PATH, mode=tf.contrib.learn.ModeKeys.EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        TIMESERIES_COL: tf.placeholder(tf.float32, [None, NUM_FEATURES])\n",
    "    }\n",
    "    features = {\n",
    "      key: tf.expand_dims(tensor, -1)\n",
    "      for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    features[TIMESERIES_COL] = tf.squeeze(features[TIMESERIES_COL], axis=[2])\n",
    "    \n",
    "    return tflearn.utils.input_fn_utils.InputFnOps(\n",
    "      features,\n",
    "      None,\n",
    "      feature_placeholders\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def experiment_fn(output_dir):\n",
    "    return tflearn.Experiment(\n",
    "        tflearn.Estimator(model_fn=model, model_dir=output_dir),\n",
    "        train_input_fn=get_train(),\n",
    "        eval_input_fn=get_valid(),\n",
    "        eval_metrics={\n",
    "            'rmse': tflearn.MetricSpec(\n",
    "                metric_fn=metrics.streaming_root_mean_squared_error\n",
    "            )\n",
    "        },\n",
    "        export_strategies=[saved_model_export_utils.make_export_strategy(\n",
    "            serving_input_fn,\n",
    "            default_output_alternative_key=None,\n",
    "            exports_to_keep=1\n",
    "        )]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shutil.rmtree('output', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn_runner.run(experiment_fn, 'output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
